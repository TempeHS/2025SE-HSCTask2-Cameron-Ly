{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "This Jupyter Notebook demonstrates various feature engineering processes you can apply to your poker dataset to improve the performance of your machine learning model. For this demonstration, we will engineer new or improved features for the poker hand dataset you previously wrangled.\n",
    "\n",
    "#### Feature Engineering Process\n",
    "- **Deriving New Variables from Existing Ones**:\n",
    "    - Encoding categorical features (e.g., encoding suits numerically or one-hot encoding them).\n",
    "    - Combining ranks and suits into a single feature (e.g., encoding a card as a unique value based on its rank and suit).\n",
    "    - Calculating new features, such as the total rank sum, the number of cards with the same rank, or the number of cards with the same suit.\n",
    "\n",
    "- **Combining Features/Feature Interactions**:\n",
    "    - Creating features that represent poker hand strength (e.g., checking for pairs, flushes, straights, etc.).\n",
    "    - Identifying patterns in the cards, such as the highest card rank or the number of consecutive ranks.\n",
    "\n",
    "- **Identifying the Most Relevant Features for the Model**:\n",
    "    - Using feature selection techniques to identify the most important features for predicting the poker hand.\n",
    "\n",
    "- **Transforming Features**:\n",
    "    - Normalizing or scaling numerical features (e.g., scaling ranks and suits to a range of 0 to 1).\n",
    "    - Applying mathematical transformations (e.g., logarithmic transformations) if necessary to reduce skewness or improve feature distribution.\n",
    "\n",
    "- **Creating Domain-Specific Features**:\n",
    "    - Incorporating poker-specific knowledge to create features that capture important characteristics of the data, such as:\n",
    "        - Whether the hand contains a flush (all cards of the same suit).\n",
    "        - Whether the hand contains a straight (consecutive ranks).\n",
    "        - The number of pairs, three-of-a-kinds, or four-of-a-kinds in the hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"poker_hand_dataset_wrangled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Deriving new variables from existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding Categorical Variables\n",
    "\n",
    "Data encoding converts categorical data, such as suits of cards, into numerical format so that it can be used as input for machine learning algorithms. Most machine learning algorithms work with numbers and not with text or categorical variables.\n",
    "\n",
    "In this dataset, the suits of cards (`Suit of Card 1`, `Suit of Card 2`, etc.) are already represented numerically (e.g., 1 for Clubs, 2 for Diamonds, 3 for Hearts, 4 for Spades). However, if needed, we can further encode these values into other formats, such as one-hot encoding, to make them more suitable for certain algorithms.\n",
    "\n",
    "For example:\n",
    "- **Label Encoding**: Suits are already encoded as integers (1 to 4).\n",
    "- **One-Hot Encoding**: Each suit can be represented as a binary vector (e.g., `[1, 0, 0, 0]` for Clubs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique ranks in the hand\n",
    "data_frame['Unique Ranks'] = data_frame[['Rank of Card 1', 'Rank of Card 2', 'Rank of Card 3', 'Rank of Card 4', 'Rank of Card 5']].apply(lambda row: len(set(row)), axis=1)\n",
    "\n",
    "# Count the number of unique suits in the hand\n",
    "data_frame['Unique Suits'] = data_frame[['Suit of Card 1', 'Suit of Card 2', 'Suit of Card 3', 'Suit of Card 4', 'Suit of Card 5']].apply(lambda row: len(set(row)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determining Poker Hand Type\n",
    "\n",
    "In poker, the type of hand (e.g., \"Flush\", \"Straight\", \"Full House\") determines its strength. This feature is critical for understanding the dataset and making predictions. We will calculate the type of poker hand based on the ranks and suits of the cards in the hand. The hand type will be added as a new column called `Hand Type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh Card\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Apply the function to determine the hand type\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m data_frame[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHand Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetermine_hand_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Display the first few rows to verify the new feature\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_frame[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRank of Card 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRank of Card 2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRank of Card 3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRank of Card 4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRank of Card 5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     43\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuit of Card 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuit of Card 2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuit of Card 3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuit of Card 4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuit of Card 5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     44\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHand Type\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mdetermine_hand_type\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      7\u001b[0m is_flush \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(suits)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Check for Straight (consecutive ranks)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m is_straight \u001b[38;5;241m=\u001b[39m ranks \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mranks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Count occurrences of each rank\u001b[39;00m\n\u001b[1;32m     13\u001b[0m rank_counts \u001b[38;5;241m=\u001b[39m {rank: ranks\u001b[38;5;241m.\u001b[39mcount(rank) \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(ranks)}\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Function to determine the type of poker hand\n",
    "def determine_hand_type(row):\n",
    "    ranks = sorted([row['Rank of Card 1'], row['Rank of Card 2'], row['Rank of Card 3'], row['Rank of Card 4'], row['Rank of Card 5']])\n",
    "    suits = [row['Suit of Card 1'], row['Suit of Card 2'], row['Suit of Card 3'], row['Suit of Card 4'], row['Suit of Card 5']]\n",
    "    \n",
    "    # Check for Flush (all suits are the same)\n",
    "    is_flush = len(set(suits)) == 1\n",
    "    \n",
    "    # Check for Straight (consecutive ranks)\n",
    "    is_straight = ranks == list(range(ranks[0], ranks[0] + 5))\n",
    "    \n",
    "    # Count occurrences of each rank\n",
    "    rank_counts = {rank: ranks.count(rank) for rank in set(ranks)}\n",
    "    rank_count_values = sorted(rank_counts.values(), reverse=True)\n",
    "    \n",
    "    # Determine hand type\n",
    "    if is_flush and is_straight and ranks[-1] == 13:  # Royal Flush\n",
    "        return 'Royal Flush'\n",
    "    elif is_flush and is_straight:  # Straight Flush\n",
    "        return 'Straight Flush'\n",
    "    elif rank_count_values == [4, 1]:  # Four of a Kind\n",
    "        return 'Four of a Kind'\n",
    "    elif rank_count_values == [3, 2]:  # Full House\n",
    "        return 'Full House'\n",
    "    elif is_flush:  # Flush\n",
    "        return 'Flush'\n",
    "    elif is_straight:  # Straight\n",
    "        return 'Straight'\n",
    "    elif rank_count_values == [3, 1, 1]:  # Three of a Kind\n",
    "        return 'Three of a Kind'\n",
    "    elif rank_count_values == [2, 2, 1]:  # Two Pair\n",
    "        return 'Two Pair'\n",
    "    elif rank_count_values == [2, 1, 1, 1]:  # One Pair\n",
    "        return 'One Pair'\n",
    "    else:  # High Card\n",
    "        return 'High Card'\n",
    "\n",
    "# Apply the function to determine the hand type\n",
    "data_frame['Hand Type'] = data_frame.apply(determine_hand_type, axis=1)\n",
    "\n",
    "# Display the first few rows to verify the new feature\n",
    "print(data_frame[['Rank of Card 1', 'Rank of Card 2', 'Rank of Card 3', 'Rank of Card 4', 'Rank of Card 5',\n",
    "                  'Suit of Card 1', 'Suit of Card 2', 'Suit of Card 3', 'Suit of Card 4', 'Suit of Card 5',\n",
    "                  'Hand Type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DoB        DoT   Age\n",
      "0   1980-07-26 2024-10-18  44.0\n",
      "1   1975-01-21 2024-01-06  49.0\n",
      "2   1983-02-10 2024-02-01  41.0\n",
      "3   1985-04-01 2024-05-09  39.0\n",
      "4   1964-02-17 2024-03-25  60.0\n",
      "..         ...        ...   ...\n",
      "434 1959-02-11 2024-02-07  65.0\n",
      "435 1966-06-09 2024-09-10  58.0\n",
      "436 1966-08-26 2024-11-27  58.0\n",
      "437 1989-08-19 2024-08-04  35.0\n",
      "438 2024-04-13 2024-04-07  -0.0\n",
      "\n",
      "[439 rows x 3 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining features/feature interactions\n",
    "\n",
    "While individual features can be powerful predictors, their interactions often carry even more information. Feature interaction engineering is the process of creating new features that represent the interaction between two or more features.\n",
    "\n",
    "In this, case some domain knowledge and data analysis have informed you that the BMI and AGE are risk multipliers (the greater the age and the greater the BMI the greater the feature). From this we can  risk value based on the feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age       BMI  Risk%\n",
      "0     44  0.346667   0.30\n",
      "1     49  0.353333   0.34\n",
      "2     41  0.183333   0.15\n",
      "3     39  0.206667   0.16\n",
      "4     60  0.353333   0.42\n",
      "..   ...       ...    ...\n",
      "434   65  0.616667   0.79\n",
      "435   58  0.723333   0.83\n",
      "436   58  0.766667   0.88\n",
      "437   35  0.876667   0.61\n",
      "438    0  0.416667   0.00\n",
      "\n",
      "[439 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the year difference and round to an integer\n",
    "data_frame['Age'] = ((data_frame['DoT'] - data_frame['DoB']).dt.days / 365.25).round().astype(int)\n",
    "\n",
    "# Create the 'Risk' column\n",
    "data_frame['Risk'] = data_frame['BMI'] * data_frame['Age']\n",
    "\n",
    "# Calculate the percentage of the maximum risk\n",
    "data_frame['Risk%'] = (data_frame['Risk'] / data_frame['Risk'].max()).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'BMI', 'Risk%']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Features\n",
    "\n",
    "Filtering is like applying the where clause in a database. It is widely used and can help when you need to work on a specific subset of your data. For our use case, let us filter the data to only include rows where the 'SEX' is 'Male'. There is no method call for this, we can just use conditional indexing to fulfil our purpose.\n",
    "\n",
    "In this, case some domain knowledge and data analysis have informed you that there is 'bimodality' in the data and males and females have a different trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  SEX  Target\n",
      "0     44   -1    25.0\n",
      "1     49   -1    31.0\n",
      "2     41   -1    37.0\n",
      "4     60   -1    39.0\n",
      "5     48   -1    40.0\n",
      "..   ...  ...     ...\n",
      "425   67   -1   303.0\n",
      "426   43   -1   306.0\n",
      "430   29   -1   310.0\n",
      "432   41   -1   317.0\n",
      "437   35   -1   346.0\n",
      "\n",
      "[234 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to -1 only\n",
    "data_frame = data_frame[data_frame['SEX'] == -1]\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'SEX', 'Target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Domain-Specific Features\n",
    "\n",
    "Domain knowledge is about understanding the domain or subject area of the data. In This case the domain is 'health' and more specifically   'Epidemiology' which is the study of how often diseases occur in different groups of people and why.\n",
    "\n",
    "The column called '1st Degree Relatives' is a domain specific feature as is records the number of family members in the individuals direct bloodline who have developed type 2 adult onset diabetes. Domain specific knowledge, is that Family history of disease in first degree relatives is a major risk factor, especially for premature events.\n",
    "\n",
    "First we will convert we will convert the FDR value to a risk percentage, because the risk can never be 0 (will never happen) or 100% (will definitely happen) we will scale the result between 0.15 and 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  FDR  FHRisk\n",
      "0     44    0    0.15\n",
      "1     49    1    0.38\n",
      "2     41    1    0.38\n",
      "4     60    0    0.15\n",
      "5     48    0    0.15\n",
      "..   ...  ...     ...\n",
      "425   67    1    0.38\n",
      "426   43    1    0.38\n",
      "430   29    2    0.62\n",
      "432   41    1    0.38\n",
      "437   35    3    0.85\n",
      "\n",
      "[234 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the family history risk\n",
    "data_frame['FHRisk'] = (data_frame['FDR'] / data_frame['FDR'].max())\n",
    "\n",
    "# Scale the result between 0.15 and 0.95\n",
    "min_val = 0.15\n",
    "max_val = 0.85\n",
    "data_frame['FHRisk'] = (((data_frame['FHRisk'] - data_frame['FHRisk'].min()) / (data_frame['FHRisk'].max() - data_frame['FHRisk'].min())) * (max_val - min_val) + min_val).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'FDR', 'FHRisk']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to make it even more meaningful, we will combine it with the `Risk` feature we engineered using the `AGE` and `BMI` features to create a combined risk 'interaction feature' that captures real-world relationships between the features.\n",
    "\n",
    "Again we will scale the result between 0.15 and 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['CombRisk'] = (data_frame['FHRisk'] * data_frame['Risk%']).round(2)\n",
    "\n",
    "min_val = 0.15\n",
    "max_val = 0.85\n",
    "data_frame['CombRisk'] = (((data_frame['CombRisk'] - data_frame['CombRisk'].min()) / (data_frame['CombRisk'].max() - data_frame['CombRisk'].min())) * (max_val - min_val) + min_val).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'Risk%', 'FHRisk', 'CombRisk']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled and engineered data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.3.Model_Training/2.3.1.model_ready_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
