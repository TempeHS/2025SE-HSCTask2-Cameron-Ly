{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Data Wrangling\n",
    "\n",
    "This is a demonstration of data wrangling using [Pandas](https://pandas.pydata.org/) the library for data analysis and manipulation.\n",
    "\n",
    "This Jupyter Notepad demonstrates different processes you can apply to your data to prepare it for feature engineering and model training. For this demonstration we will wrangle the poker hand data set you previewed in the last Jupyter Notebook.\n",
    "\n",
    "> [!Note]\n",
    "> None of these processes are destructive to the source CSV as long as you save the modified data to a new CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"poker_hand_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "Null values during data analysis can cause runtime errors and unexpected results. It is important to identify null values and deal with them appropriately before training a model.\n",
    "\n",
    "The `isnull().sum()` method call returns the null values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suit of Card 1    0\n",
       "Suit of Card 2    0\n",
       "Suit of Card 3    0\n",
       "Suit of Card 4    0\n",
       "Suit of Card 5    0\n",
       "Rank of Card 1    0\n",
       "Rank of Card 2    0\n",
       "Rank of Card 3    0\n",
       "Rank of Card 4    0\n",
       "Rank of Card 5    0\n",
       "Poker Hand        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Data Check\n",
    "\n",
    "Shown below is the result of checking for null values in the dataset. As we can see, there are no null values in any of the columns, indicating that the dataset is clean and ready for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suit of Card 1    0\n",
       "Suit of Card 2    0\n",
       "Suit of Card 3    0\n",
       "Suit of Card 4    0\n",
       "Suit of Card 5    0\n",
       "Rank of Card 1    0\n",
       "Rank of Card 2    0\n",
       "Rank of Card 3    0\n",
       "Rank of Card 4    0\n",
       "Rank of Card 5    0\n",
       "Poker Hand        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "\n",
    "Duplicate data can have detrimental effects on your machine learning models and outcomes, such as reducing data diversity and representativeness, which can lead to overfitting or biased models.\n",
    "\n",
    "The `duplicated().sum()` method call returns the count of duplicate rows in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drop_duplicates()` method call can be then stored back onto the data_frame variable removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace Data\n",
    "\n",
    "We can run a lambda function on a column to modify its values. For example, if we wanted to standardize the format of card suits or ranks, we could convert them to lowercase or encode them numerically. To run a function over a complete column, we can use the `apply` method, which iterates over each row and modifies the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    4\n",
       "2    2\n",
       "3    3\n",
       "4    1\n",
       "Name: Suit of Card 1, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the format of card suits in the 'Suit of Card 1' column\n",
    "data_frame['Suit of Card 1'] = data_frame['Suit of Card 1'].apply(lambda x: str(x).lower())\n",
    "\n",
    "# Preview the changes\n",
    "data_frame['Suit of Card 1'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that there are no data entry errors by the `unique()` method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values before conversion: ['4' '2' '3' '1']\n",
      "Data type: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values before conversion:\", data_frame['Suit of Card 1'].unique())\n",
    "print(\"Data type:\", data_frame['Suit of Card 1'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Text Suits: ['Spades' 'Diamonds' 'Hearts' 'Clubs']\n"
     ]
    }
   ],
   "source": [
    "# Define the suit mapping\n",
    "suit_mapping = {\n",
    "    1: 'Clubs',\n",
    "    2: 'Diamonds',\n",
    "    3: 'Hearts',\n",
    "    4: 'Spades'\n",
    "}\n",
    "\n",
    "# Ensure that 'Suit of Card 1' is of integer type\n",
    "data_frame['Suit of Card 1'] = data_frame['Suit of Card 1'].astype(int)\n",
    "\n",
    "# Map the numeric suits to text suits\n",
    "data_frame['Suit of Card 1 Text'] = data_frame['Suit of Card 1'].map(lambda x: suit_mapping.get(x, 'unknown'))\n",
    "\n",
    "# Check the results\n",
    "print(\"Mapped Text Suits:\", data_frame['Suit of Card 1 Text'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers\n",
    "\n",
    "Outliers can skew your analysis on numerical columns, and it is important to remove them. We can use the 25th and 75th quartile on numerical data, to get the inter-quartile range. This allows us to estimate an acceptable range, and we can then filter out any values outside this range. Mathematically, outliers are values occurring outside 1.5 times the interquartile range (IQR) from the first quartile (Q1) or third quartile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    49998.000000\n",
      "mean         7.997800\n",
      "std          3.736083\n",
      "min          2.000000\n",
      "25%          5.000000\n",
      "50%          8.000000\n",
      "75%         11.000000\n",
      "max         14.000000\n",
      "Name: Rank of Card 1, dtype: float64\n",
      "Outliers are a Rank of Card 1 above 20.0 or below -4.0\n"
     ]
    }
   ],
   "source": [
    "# Get the interquartile range (IQR) for the 'Rank of Card 1' column\n",
    "print(data_frame['Rank of Card 1'].describe())\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = data_frame['Rank of Card 1'].quantile(0.25)\n",
    "Q3 = data_frame['Rank of Card 1'].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers\n",
    "print(f'Outliers are a Rank of Card 1 above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    49998.000000\n",
      "mean         1.621705\n",
      "std          1.487787\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          3.000000\n",
      "max          9.000000\n",
      "Name: Poker Hand, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter rows within the acceptable range for 'Poker Hand'\n",
    "data_frame = data_frame[(data_frame['Poker Hand'] >= Q1 - 1.5 * IQR) & (data_frame['Poker Hand'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "# Display the descriptive statistics for the filtered data\n",
    "print(data_frame['Poker Hand'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if Columns Are Already Scaled\n",
    "\n",
    "Before scaling the features, it is important to check if they are already scaled. Scaled features typically have values within a specific range, such as 0 to 1 for Min-Max scaling.\n",
    "\n",
    "To check if a column is already scaled:\n",
    "1. Inspect the minimum and maximum values of the column.\n",
    "2. If the values are between 0 and 1, the column is likely already scaled.\n",
    "3. If the values are outside this range, scaling may be required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rechecking ranges for rank columns:\n",
      "Rank of Card 1: Min = nan, Max = nan\n",
      "Rank of Card 2: Min = nan, Max = nan\n",
      "Rank of Card 3: Min = nan, Max = nan\n",
      "Rank of Card 4: Min = nan, Max = nan\n",
      "Rank of Card 5: Min = nan, Max = nan\n",
      "\n",
      "Rechecking ranges for suit columns:\n",
      "Suit of Card 1: Min = nan, Max = nan\n",
      "Suit of Card 2: Min = nan, Max = nan\n",
      "Suit of Card 3: Min = nan, Max = nan\n",
      "Suit of Card 4: Min = nan, Max = nan\n",
      "Suit of Card 5: Min = nan, Max = nan\n"
     ]
    }
   ],
   "source": [
    "# Define rank and suit columns\n",
    "rank_columns = ['Rank of Card 1', 'Rank of Card 2', 'Rank of Card 3', 'Rank of Card 4', 'Rank of Card 5']\n",
    "suit_columns = ['Suit of Card 1', 'Suit of Card 2', 'Suit of Card 3', 'Suit of Card 4', 'Suit of Card 5']\n",
    "\n",
    "# Filter out invalid rank values\n",
    "for column in rank_columns:\n",
    "    data_frame = data_frame[data_frame[column].between(1, 13)]\n",
    "\n",
    "# Scale the rank columns\n",
    "MIN_RANK = 1\n",
    "MAX_RANK = 13\n",
    "for column in rank_columns:\n",
    "    data_frame[column] = [(X - MIN_RANK) / (MAX_RANK - MIN_RANK) for X in data_frame[column]]\n",
    "\n",
    "# Scale the suit columns (optional)\n",
    "MIN_SUIT = 1\n",
    "MAX_SUIT = 4\n",
    "for column in suit_columns:\n",
    "    data_frame[column] = [(X - MIN_SUIT) / (MAX_SUIT - MIN_SUIT) for X in data_frame[column]]\n",
    "\n",
    "# Check the ranges again\n",
    "print(\"Rechecking ranges for rank columns:\")\n",
    "for column in rank_columns:\n",
    "    print(f\"{column}: Min = {data_frame[column].min()}, Max = {data_frame[column].max()}\")\n",
    "\n",
    "print(\"\\nRechecking ranges for suit columns:\")\n",
    "for column in suit_columns:\n",
    "    print(f\"{column}: Min = {data_frame[column].min()}, Max = {data_frame[column].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!important]\n",
    "> You need to save the calculations for each dataset you scale for scaling new values for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('poker_hand_dataset_wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
